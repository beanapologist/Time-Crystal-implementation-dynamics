# First cell - Installation and imports
!pip install torch numpy matplotlib pandas tqdm ipywidgets

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm
import math
from typing import Dict, List, Tuple
from IPython.display import clear_output

# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Second cell - Dataset Class
class QuantumDataset(Dataset):
    def __init__(self, size: int = 1000, feature_dim: int = 16):
        super().__init__()
        self.size = size
        self.feature_dim = feature_dim
        
        # Generate quantum-influenced features
        quantum_noise = 0.1 * torch.sin(torch.randn(size, 1) * np.pi)
        
        # Create feature matrix with quantum parameters
        self.data = torch.randn(size, feature_dim) * 0.1
        
        # Enhanced spacetime warp
        spacetime_warp = torch.exp(
            F.layer_norm(self.data[:, :4], (4,)).sum(dim=1, keepdim=True) / 2
        )
        
        # Quantum entanglement
        quantum_entanglement = torch.tanh(
            self.data[:, 4:8].prod(dim=1, keepdim=True) * 0.1
        )
        
        # Phase coherence
        phase_coherence = torch.sigmoid(
            F.layer_norm(self.data[:, 8:12], (4,)).sum(dim=1, keepdim=True)
        )
        
        # Reality stability
        reality_stability = torch.tanh(
            F.layer_norm(self.data[:, 12:], (4,)).sum(dim=1, keepdim=True)
        )
        
        # Combined quantum targets
        self.targets = (
            spacetime_warp * quantum_entanglement + 
            phase_coherence * reality_stability +
            quantum_noise
        ) * 0.5

    def __len__(self) -> int:
        return self.size

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        return self.data[idx], self.targets[idx]

# Third cell - Model Class
class QuantumNet(nn.Module):
    def __init__(self, input_dim: int = 16, hidden_dim: int = 128):
        super().__init__()
        
        # Quantum substrate initialization
        self.substrate_size = 1024
        self.quantum_substrate = nn.Parameter(
            torch.randn(self.substrate_size, self.substrate_size, dtype=torch.complex64)
        )
        
        # Neural network layers
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim * 2)
        self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, 1)
        
        # Quantum parameters
        self.time_warp = nn.Parameter(torch.tensor(0.1))
        self.quantum_coupling = nn.Parameter(torch.tensor(0.15))
        self.reality_integrity = nn.Parameter(torch.tensor(0.5))
        self.phase_coherence = nn.Parameter(torch.tensor(0.8))
        
        # Normalization and regularization
        self.layer_norm1 = nn.LayerNorm(hidden_dim)
        self.layer_norm2 = nn.LayerNorm(hidden_dim * 2)
        self.layer_norm3 = nn.LayerNorm(hidden_dim)
        self.dropout = nn.Dropout(0.1)

    def quantum_transform(self, x: torch.Tensor) -> torch.Tensor:
        # Apply quantum effects
        phase = torch.exp(1j * self.time_warp * math.pi)
        coherence = F.sigmoid(self.phase_coherence)
        return x * coherence * torch.real(phase)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Initial quantum transformation
        x = self.quantum_transform(x)
        
        # Neural network with quantum coupling
        x = self.dropout(F.silu(self.layer_norm1(self.fc1(x))))
        x = x * self.quantum_coupling
        
        x = self.dropout(F.silu(self.layer_norm2(self.fc2(x))))
        x = x * self.reality_integrity
        
        x = self.dropout(F.silu(self.layer_norm3(self.fc3(x))))
        x = x * self.phase_coherence
        
        # Reality breach calculation
        reality_breach = torch.tanh(x.mean(dim=1, keepdim=True))
        x = self.fc4(x) + reality_breach * self.reality_integrity
        
        return x

# Fourth cell - Training Class
class QuantumTrainer:
    def __init__(self, model: nn.Module, config: Dict):
        self.model = model
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
        # Optimizer setup
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=config['learning_rate'],
            weight_decay=config['weight_decay']
        )
        
        # Learning rate scheduler
        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(
            self.optimizer,
            max_lr=config['learning_rate'],
            epochs=config['epochs'],
            steps_per_epoch=config['steps_per_epoch'],
            pct_start=0.3
        )
        
        # Loss function
        self.criterion = nn.MSELoss()
        
        # Metrics tracking
        self.metrics = {
            'train_loss': [],
            'val_loss': [],
            'time_warp': [],
            'quantum_coupling': [],
            'reality_integrity': [],
            'phase_coherence': [],
            'learning_rate': []
        }
        
        self.best_loss = float('inf')

    def train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        self.model.train()
        total_loss = 0
        
        for batch in train_loader:
            data, targets = [b.to(self.device) for b in batch]
            
            self.optimizer.zero_grad()
            outputs = self.model(data)
            
            # Calculate loss with quantum regularization
            loss = self.criterion(outputs, targets)
            quantum_reg = (
                self.model.time_warp ** 2 + 
                self.model.quantum_coupling ** 2
            ) * 0.01
            loss += quantum_reg
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
            self.optimizer.step()
            self.scheduler.step()
            
            total_loss += loss.item()
        
        return {
            'loss': total_loss / len(train_loader),
            'time_warp': self.model.time_warp.item(),
            'quantum_coupling': self.model.quantum_coupling.item(),
            'reality_integrity': self.model.reality_integrity.item(),
            'phase_coherence': self.model.phase_coherence.item(),
            'learning_rate': self.scheduler.get_last_lr()[0]
        }

    def validate(self, val_loader: DataLoader) -> float:
        self.model.eval()
        total_loss = 0
        
        with torch.no_grad():
            for batch in val_loader:
                data, targets = [b.to(self.device) for b in batch]
                outputs = self.model(data)
                loss = self.criterion(outputs, targets)
                total_loss += loss.item()
        
        return total_loss / len(val_loader)

    def plot_metrics(self):
        plt.figure(figsize=(20, 10))
        
        # Loss plot
        plt.subplot(2, 2, 1)
        plt.plot(self.metrics['train_loss'], label='Train')
        plt.plot(self.metrics['val_loss'], label='Validation')
        plt.title('Loss')
        plt.xlabel('Epoch')
        plt.legend()
        
        # Quantum parameters
        plt.subplot(2, 2, 2)
        plt.plot(self.metrics['time_warp'], label='Time Warp')
        plt.plot(self.metrics['quantum_coupling'], label='Q-Coupling')
        plt.plot(self.metrics['reality_integrity'], label='Reality')
        plt.plot(self.metrics['phase_coherence'], label='Coherence')
        plt.title('Quantum Parameters')
        plt.xlabel('Epoch')
        plt.legend()
        
        # Learning rate
        plt.subplot(2, 2, 3)
        plt.plot(self.metrics['learning_rate'])
        plt.title('Learning Rate')
        plt.xlabel('Epoch')
        
        plt.tight_layout()
        plt.show()

    def train(self, train_loader: DataLoader, val_loader: DataLoader):
        for epoch in range(self.config['epochs']):
            # Training
            train_metrics = self.train_epoch(train_loader)
            val_loss = self.validate(val_loader)
            
            # Store metrics
            self.metrics['train_loss'].append(train_metrics['loss'])
            self.metrics['val_loss'].append(val_loss)
            self.metrics['time_warp'].append(train_metrics['time_warp'])
            self.metrics['quantum_coupling'].append(train_metrics['quantum_coupling'])
            self.metrics['reality_integrity'].append(train_metrics['reality_integrity'])
            self.metrics['phase_coherence'].append(train_metrics['phase_coherence'])
            self.metrics['learning_rate'].append(train_metrics['learning_rate'])
            
            # Save best model
            if val_loss < self.best_loss:
                self.best_loss = val_loss
                torch.save(self.model.state_dict(), 'best_quantum_model.pth')
            
            # Print metrics
            print(f"\nEpoch {epoch+1}/{self.config['epochs']}")
            print(f"Train Loss: {train_metrics['loss']:.6f}")
            print(f"Val Loss: {val_loss:.6f}")
            print(f"Time Warp: {train_metrics['time_warp']:.6f}")
            print(f"Quantum Coupling: {train_metrics['quantum_coupling']:.6f}")
            print(f"Reality Integrity: {train_metrics['reality_integrity']:.6f}")
            print(f"Phase Coherence: {train_metrics['phase_coherence']:.6f}")
            print(f"Learning Rate: {train_metrics['learning_rate']:.6f}")
            
            # Plot every 10 epochs
            if (epoch + 1) % 10 == 0:
                clear_output(wait=True)
                self.plot_metrics()

# Fifth cell - Training Setup and Execution
def main():
    # Configuration
    config = {
        'batch_size': 32,
        'learning_rate': 1e-3,
        'weight_decay': 1e-5,
        'hidden_dim': 128,
        'epochs': 100,
        'steps_per_epoch': 50
    }

    # Create datasets
    train_dataset = QuantumDataset(size=2000)
    val_dataset = QuantumDataset(size=500)
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=2
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=2
    )
    
    # Initialize model
    model = QuantumNet(hidden_dim=config['hidden_dim'])
    
    # Initialize trainer
    trainer = QuantumTrainer(model, config)
    
    # Train model
    trainer.train(train_loader, val_loader)
    
    return model, trainer

# Sixth cell - Run training
if __name__ == "__main__":
    model, trainer = main()